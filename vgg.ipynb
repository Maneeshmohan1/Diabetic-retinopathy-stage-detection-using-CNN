{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 159s 3us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications import VGG16\n",
    "vgg_model = VGG16(weights='imagenet',\n",
    "                               include_top=False,\n",
    "                               input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the models' architecture and layer names, run the following\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teqip-cek/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "# Creating dictionary that maps layer names to the layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
    "\n",
    "# Getting output tensor of the last VGG layer that we want to include\n",
    "x = layer_dict['block2_pool'].output\n",
    "\n",
    "# Stacking a new simple convolutional network on top of it    \n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# Creating new model. Please note that this is NOT a Sequential() model.\n",
    "from keras.models import Model\n",
    "custom_model = Model(input=vgg_model.input, output=x)\n",
    "\n",
    "# Make sure that the pre-trained bottom layers are not trainable\n",
    "for layer in custom_model.layers[:7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Do not forget to compile it\n",
    "custom_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='rmsprop',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 35, 35, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4735232   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 5,070,469\n",
      "Trainable params: 4,810,309\n",
      "Non-trainable params: 260,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 413 images belonging to 5 classes.\n",
      "Found 103 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('/home/teqip-cek/Desktop/chandhuP/Training',target_size = (150, 150),batch_size = 32,class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('/home/teqip-cek/Desktop/chandhuP//Testing',target_size = (150, 150),batch_size = 32,class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training....\n",
      "Epoch 1/25\n",
      "20/20 [==============================] - 206s 10s/step - loss: 10.8677 - acc: 0.3185 - val_loss: 13.0139 - val_acc: 0.1926\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 13.01387, saving model to models/vgg.hdf5\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 137s 7s/step - loss: 12.9679 - acc: 0.1940 - val_loss: 13.1333 - val_acc: 0.1852\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 13.01387\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 128s 6s/step - loss: 13.3298 - acc: 0.1730 - val_loss: 13.1333 - val_acc: 0.1852\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 13.01387\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 132s 7s/step - loss: 13.1305 - acc: 0.1854 - val_loss: 13.3341 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 13.01387\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 122s 6s/step - loss: 13.3802 - acc: 0.1699 - val_loss: 13.1333 - val_acc: 0.1852\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 13.01387\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 131s 7s/step - loss: 13.2085 - acc: 0.1805 - val_loss: 12.8945 - val_acc: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss improved from 13.01387 to 12.89448, saving model to models/vgg.hdf5\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 159s 8s/step - loss: 13.2745 - acc: 0.1764 - val_loss: 13.6108 - val_acc: 0.1556\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 12.89448\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 122s 6s/step - loss: 12.9438 - acc: 0.1969 - val_loss: 12.8945 - val_acc: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 12.89448\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 125s 6s/step - loss: 13.3323 - acc: 0.1728 - val_loss: 12.8945 - val_acc: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 12.89448\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 127s 6s/step - loss: 13.1706 - acc: 0.1829 - val_loss: 13.4914 - val_acc: 0.1630\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 12.89448\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 123s 6s/step - loss: 13.2163 - acc: 0.1800 - val_loss: 13.0139 - val_acc: 0.1926\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 12.89448\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 116s 6s/step - loss: 13.2160 - acc: 0.1801 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 12.89448\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 116s 6s/step - loss: 13.2713 - acc: 0.1766 - val_loss: 12.8945 - val_acc: 0.2000\n",
      "\n",
      "Epoch 00013: val_loss improved from 12.89448 to 12.89448, saving model to models/vgg.hdf5\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 116s 6s/step - loss: 13.2592 - acc: 0.1774 - val_loss: 13.3720 - val_acc: 0.1704\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 12.89448\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 117s 6s/step - loss: 13.1631 - acc: 0.1833 - val_loss: 13.1333 - val_acc: 0.1852\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 12.89448\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 113s 6s/step - loss: 13.3777 - acc: 0.1700 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 12.89448\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 114s 6s/step - loss: 13.0421 - acc: 0.1908 - val_loss: 13.3720 - val_acc: 0.1704\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 12.89448\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 118s 6s/step - loss: 13.2163 - acc: 0.1800 - val_loss: 12.8945 - val_acc: 0.2000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 12.89448\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 117s 6s/step - loss: 13.2486 - acc: 0.1780 - val_loss: 13.3720 - val_acc: 0.1704\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 12.89448\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 115s 6s/step - loss: 13.4657 - acc: 0.1646 - val_loss: 12.8945 - val_acc: 0.2000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 12.89448\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 114s 6s/step - loss: 13.1784 - acc: 0.1824 - val_loss: 12.7751 - val_acc: 0.2074\n",
      "\n",
      "Epoch 00021: val_loss improved from 12.89448 to 12.77508, saving model to models/vgg.hdf5\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 122s 6s/step - loss: 13.1332 - acc: 0.1852 - val_loss: 13.4914 - val_acc: 0.1630\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 12.77508\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 129s 6s/step - loss: 13.1454 - acc: 0.1844 - val_loss: 13.0139 - val_acc: 0.1926\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 12.77508\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 116s 6s/step - loss: 13.2819 - acc: 0.1760 - val_loss: 13.3341 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 12.77508\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 114s 6s/step - loss: 13.1379 - acc: 0.1849 - val_loss: 13.2527 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 12.77508\n",
      "training finished!!\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "custom_model_json= custom_model.to_json()\n",
    "with open(\"models/model.vgg\",\"w\") as json_file:\n",
    "    json_file.write(custom_model_json)\n",
    "print('starting training....')\n",
    "checkpointer = ModelCheckpoint(filepath=\"models/vgg.hdf5\", verbose=1, save_best_only=True)\n",
    "history = custom_model.fit_generator(generator=training_set, steps_per_epoch=413//20,epochs=515//20,validation_data=test_set,validation_steps=102//20,callbacks=[checkpointer])\n",
    "print('training finished!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
